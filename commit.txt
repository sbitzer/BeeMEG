doing GLM inference after source reconstruction

Trying to become more certain about the results I finally implemented the
procedure as originally suggested by Burkhard as a potentially alternative path
to reach the same effects and thus verify these effects. So I now do source
reconstruction for the MEG signals in each epoch and then do inference directly
in source space.

Source reconstruction
---------------------
Is implemented in:
        reconstruct_sources_from_epochs.py

I use baseline correction as motivated by my last analysis and use the baseline
period to estimate the covariance between sensors for source reconstruction.
Further, source reconstruction is now done based on all MEG sensors including
the gradiometers.  I also had to choose a regularisation constant lambda and
just assumed a signal-to-noise ratio of 3 for that without necessarily knowing
whether this applies to my data, but it's used like that in the MNE example
called "Compute MNE-dSPM inverse solution on single epochs".

I had to chunk the data (choice: by subjects) to avoid memory issues. Apparently
16GB of RAM are not sufficient to hold all of the data in memory even when it's
reduced from 8000 sources to only 362 areas. This is a bit strange as the data
should only fill about 4GB of memory when I assume 64 bit floats. Perhaps this
is an issue of how pandas represents the data in a Dataframe which includes the
indeces. Anyway, DO NOT TRY to load individual columns in the hdf-file, as this
file format is only efficient for row-wise access. If you try to selectively
load columns, the whole file will first be loaded and columns will be selected
afterwards, filling up memory quickly.

I only store the average (mean_flip) activations of the Glasser areas, but
noticed that the resulting mean effects and their variance across subjects can
be very different (e.g. small effects, small variance for sensorimotor areas,
but large effects, large variance for v23ab). I guess that this is due to
averaging activated and non-activated subparts of individual areas and,
specifically, different number of vertices in the areas, but I haven't checked
that explicitly, yet.

Inference (sequential)
----------------------
is implemented in:
        infer_sequential_source.py
        second_level_abs_inference.py

As I stayed consistent in how I store the data, most parts of the code simply
apply to the data in source space, too (replacing sensors with labels/areas). I
still had to write a new GLM-inference script, because I now need to load data
of subjects sequentially to avoid memory issues. As I reduce the data from 480
trials to 12 regressors and from 90 to 50 time points, memory is no issue for
the inference results, though.

I decided to include dot_x_cflip and accev_cflip, because it should not hurt.
For now I also use trialsregs_dot=5, because trial-regressors should not have
dot-aligned effects. I left rt_thresh at 0.1 and computed 5 permutations.

Computations take a while. I would estimate roughly 5 hours per permutation.

Once I have the GLM inference results, I can run second_level_abs_inference
without changes (except for adaptation of data loading). It turned out that my
p_thresh of 0.5 is far too high for the raw GLM results. This is because the
scaling of the data in source space is different when I do source
reconstruction based on the GLM results. The raw GLM betas can be roughly
interpreted as the percentage of variance that the corresponding regressor
explains and these values reach 0.1 for strong effects, but remain around 0.02
for smallish effects. They never reach 0.5. Perhaps p_thresh=0.02 would be a
reasonable value, but for now I switched to looking at mu_t instead.

Results
-------
are stored in:
        source_epochs_allsubs_HCPMMP1_201706131725.h5 (raw source data)
        source_sequential_201706141650.h5 (GLM inference results)
        source_sequential_201706141650_slabs_[r_name].h5

where the last is the file pattern for the second level results computed with
second_level_abs_inference.

Results can be viewed in MEG_sequential.ipynb and with show_labels_tmp.py as
before. I have now also included plots of across-subject variance of inferred
betas through time following my corresponding plot at the sensor level in 
example_results.ipynb.

Comparison to previous results
..............................
Results are more different to previous results than I expected [update: maybe 
not]. Most saliently,
I now see clearer effects in early visual cortex (V2, V3: at 110; left V2: at 
170 ms; V4: between 200 and 300 ms) and
in sensorimotor regions (4, 3a, 3b, 1: from 300 ms; 2: at 170 ms and from 300 
ms). It also appears that there are now more effects in dorsolateral prefrontal
cortex and inferior frontal cortex, but they remain weak in comparison to other 
effects and are often isolated in time. I did not investigate differences in 
results more systematically. [update: quick check showed that there were 
effects in early visual and sensorimotor areas in previous results, too, but 
less strongly]

Consistent with my previous results I see strong effects in the posterior 
cingulate cortex. These are now generally stronger with some additional areas
being activated, but generally results appear to be consistent with results
before. For example, right DVT is activated around 170 ms and from about 380 ms
in both results. Also v23ab is bilaterally activated at 110 ms and from 300 ms 
in both results, but the new results additionally show a smaller peak at 
170 ms, too.

In general, it appears that the new results are a bit clearer, mostly because
previous effects were enhanced. 
